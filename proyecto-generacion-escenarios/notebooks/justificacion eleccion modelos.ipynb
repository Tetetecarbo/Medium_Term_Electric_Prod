{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load libraries ###\n",
    "\n",
    "# interactive plotting\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "sns.set()\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (10, 7), 'figure.dpi': 120})\n",
    "\n",
    "# Data management libraries\n",
    "import itertools\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import sklearn.mixture as mixture\n",
    "from scipy import linalg\n",
    "import math\n",
    "\n",
    "# Other\n",
    "from mltools import unsupervised_tools as UT\n",
    "\n",
    "# Import data\n",
    "\n",
    "# Load data\n",
    "eolica = pd.read_csv(\"eolica.csv\")\n",
    "\n",
    "df = eolica\n",
    "numeric_inputs = ['Tmax','Tmin','Tmed','Rmed','Vmax','Pmed_00_24','Pmed_00_06','Pmed_06_12', 'Pmed_12_18','Pmed_18_24']\n",
    "X = df[numeric_inputs]\n",
    "Y = df[['gen']]\n",
    "\n",
    "# Preprocessing the values to perform PCA\n",
    "numeric_features = X.select_dtypes(include=['int64','float64']).columns.values.tolist()\n",
    "scaler = StandardScaler()\n",
    "X_transformed = scaler.fit_transform(X=X)\n",
    "\n",
    "## PCA -----------------------------------------------------------\n",
    "pca = PCA(n_components=len(X.columns),) #num de variables\n",
    "X_pca = pca.fit_transform(X_transformed)\n",
    "\n",
    "exp_variance = pd.DataFrame(data=pca.explained_variance_ratio_, index = ['PC' + str(n_pca + 1) for n_pca in range(pca.n_components)], columns=['Exp_variance'])\n",
    "exp_variance['cum_Exp_variance'] = exp_variance['Exp_variance'].cumsum()\n",
    "exp_variance\n",
    "\n",
    "## PCA -----------------------------------------------------------\n",
    "'''\n",
    "Con esto se ve que ncomponents tiene que ser 5 para que el \n",
    "95% de la varianza sea explicada\n",
    "\n",
    "pca = PCA(n_components=X_transformed.shape[1],)\n",
    "X_pca = pca.fit_transform(X_transformed)\n",
    "\n",
    "sns.barplot(data=exp_variance, x=exp_variance.index, y='Exp_variance', color='gray')\n",
    "sns.lineplot(data=exp_variance, x=exp_variance.index, y='cum_Exp_variance', color='blue', label='Cumulative Proportion')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "## PCA -----------------------------------------------------------\n",
    "pca = PCA(n_components=5,) #95% of variance\n",
    "X_pca = pca.fit_transform(X_transformed)\n",
    "\n",
    "# Print the PCs\n",
    "# loadings = pd.DataFrame(pca.components_.T * np.sqrt(pca.explained_variance_), columns=['PC' + str(pca + 1) for pca in range(pca.n_components)], index=numeric_inputs)\n",
    "\n",
    "# fig, axes = plt.subplots(4, 1, figsize=(16,9))\n",
    "# PC = 0\n",
    "# for ax in axes.ravel():\n",
    "#     sns.barplot(data=loadings, x=loadings.index, y=loadings.columns.values.tolist()[PC], color='gray', ax=ax)\n",
    "#     PC += 1\n",
    "\n",
    "# df_pca = pd.DataFrame(X_pca, columns=['PC' + str(n_pca + 1) for n_pca in range(pca.n_components)])\n",
    "# df_pca['gen'] = Y.values\n",
    "# df_pca['ccaa'] = df['ccaa']\n",
    "\n",
    "# sns.lmplot(x='PC1', y='PC2', data=df_pca, hue='ccaa', fit_reg=False, scatter_kws={'alpha':0.5})\t\n",
    "# plt.show()\n",
    "\n",
    "## Use gaussian mixture if you want to specify number of kernels\n",
    "lowest_bic = np.infty\n",
    "bic = []\n",
    "n_components_range = range(1, 13)\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        # Fit a Gaussian mixture with EM\n",
    "        gmm = mixture.GaussianMixture(n_components=n_components,\n",
    "                                covariance_type=cv_type)\n",
    "        gmm.fit(X_pca)\n",
    "        bic.append(gmm.bic(X_pca))\n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm\n",
    "\n",
    "bic = np.array(bic)\n",
    "color_iter = itertools.cycle(['navy', 'turquoise', 'cornflowerblue', 'darkorange', 'green', 'red', 'blue', 'gray', 'brown', 'purple', 'pink', 'yellow'])\n",
    "gmm = mixture.GaussianMixture(n_components=6, covariance_type=cv_type)\n",
    "gmm.fit(X_pca)\n",
    "clf = gmm\n",
    "bars = []\n",
    "\n",
    "# Plot the BIC scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "spl = plt.subplot(2, 1, 1)\n",
    "for i, (cv_type, color) in enumerate(zip(cv_types, color_iter)):\n",
    "    xpos = np.array(n_components_range) + .2 * (i - 2)\n",
    "    bars.append(plt.bar(xpos, bic[i * len(n_components_range):\n",
    "                                  (i + 1) * len(n_components_range)],\n",
    "                        width=.2, color=color))\n",
    "plt.xticks(n_components_range)\n",
    "plt.ylim([bic.min() * 1.01 - .01 * bic.max(), bic.max()])\n",
    "plt.title('BIC score per model')\n",
    "xpos = np.mod(bic.argmin(), len(n_components_range)) + .65 +\\\n",
    "    .2 * np.floor(bic.argmin() / len(n_components_range))\n",
    "plt.text(xpos, bic.min() * 0.97 + .03 * bic.max(), '*', fontsize=14)\n",
    "spl.set_xlabel('Number of components')\n",
    "spl.legend([b[0] for b in bars], cv_types)\n",
    "\n",
    "# Plot the winner\n",
    "splot = plt.subplot(2, 1, 2)\n",
    "Y_ = clf.predict(X_pca)\n",
    "for i, (mean, cov, color) in enumerate(zip(clf.means_, clf.covariances_,\n",
    "                                           color_iter)):\n",
    "    v, w = linalg.eigh(cov)\n",
    "    if not np.any(Y_ == i):\n",
    "        continue\n",
    "    plt.scatter(X_pca[Y_ == i, 0], X_pca[Y_ == i, 1], .8, color=color)\n",
    "\n",
    "    # Plot an ellipse to show the Gaussian component\n",
    "    angle = np.arctan2(w[0][1], w[0][0])\n",
    "    angle = 180. * angle / np.pi  # convert to degrees\n",
    "    v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "    ell = mpl.patches.Ellipse(mean, width=v[0], height=v[1], angle=180. + angle, color=color)\n",
    "    ell.set_clip_box(splot.bbox)\n",
    "    ell.set_alpha(.5)\n",
    "    splot.add_artist(ell)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Selected GMM: full model, %i components' % clf.n_components)\n",
    "plt.subplots_adjust(hspace=.35, bottom=.02)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Definir el número de escenarios y el tamaño de cada escenario\n",
    "scenario_size = 1000\n",
    "scenario_samples, _ = clf.sample(scenario_size)\n",
    "scenario_df = pd.DataFrame(scenario_samples, columns=[f'PC{i+1}' for i in range(scenario_samples.shape[1])])\n",
    "\n",
    "x_scenarios = pca.inverse_transform(scenario_samples) # Inverse transform the scenarios\n",
    "x_scenarios = pd.DataFrame(scaler.inverse_transform(x_scenarios), columns=numeric_inputs) # Inverse scale the scenarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
